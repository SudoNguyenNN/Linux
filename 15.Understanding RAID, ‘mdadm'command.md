**RAID (Redundant Arrays of Inexpensive Disk)** (Hệ thống đĩa dự phòng). Đây là hệ thống hoạt động bằng cách kết nối một dãy các ổ cứng lại với nhau để hình thành một thiết bị nhớ.Được sử dụng như một giải pháp phòng hộ vì nó cho phép ghi dữ liệu lên nhiều đĩa cứng cùng lúc.

**Lợi thế của RAID**

**Có ba lý do chính để áp dụng RAID:**

Tính dự phòng
Hiệu quả cao
Chi phí thấp

**RAID được chia thành các loại**

**RAID 0**

RAID 0 sử dụng một kỹ thuật gọi là "striping". "Striping" phân chia khối dữ liệu đơn và trải chúng ra các ổ cứng.Tác dụng của striping là lằm tăng hiệu quả thực thi.Có thể ghi được hai khối dữ liệu cùng lúc với hai ổ cứng.

<img src="https://camo.githubusercontent.com/350432a2915996bf5e76b6bd7e6e13d90cb4b083/68747470733a2f2f692e696d6775722e636f6d2f4f6372524330362e6a7067">

Lợi ích:

- Tăng hiệu quả lưu trữ
- Không làm mất dung lượng dữ liệu

Bất lợi:

- Không có ổ dự phòng
- 
**RAID 1**

RAID 1 cung cấp phương pháp dự phòng dữ liệu đơn giản bằng kỹ thuật "mirroring" (nhân bản dữ liệu). Kỹ thật này cần hai ổ cứng riêng biệt có cùng dung lượng, một ổ sẽ hoạt động một ổ sẽ dự phòng, khi dữ liệu được ghi vào ổ hoạt động thì đồng thời nó cũng được ghi vào ổ dự phòng.

<img src="https://camo.githubusercontent.com/58f9445a200d87a8dd4e05f8b2edb7b8adf6100a/68747470733a2f2f692e696d6775722e636f6d2f526e457361306d2e6a7067">

Lợi ích:

- Cung cấp dự phòng dữ liệu toàn diện hơn.

Bất lợi:

- Dung lượng lưu trữ chỉ bằng dung lượng ổ nhỏ nhất.
- Không cải thiện hiệu suất.

**RAID 0+1**

Đây là sự kết hợp RAID mà một số hãng sản xuất đã thực hiện để gộp các lợi ích của hai phiên bản lại với nhau. Sự kết hợp này cần ít nhất 4 ổ cứng.

<img src="https://camo.githubusercontent.com/cb0fe174c6936c1d4cf82ec5c60a2f418bcd6665/68747470733a2f2f692e696d6775722e636f6d2f753455504163722e706e67">

Lợi ích:

- Tăng hiệu quả thực thi
- Dữ liệu được dự phòng toàn bộ

Bất lợi:

- Yêu cầu số lượng ổ cứng lớn
- Khả năng truy xuất dữ liệu giảm.

**RAID 10 hay RAID 1+0**

RAID 10 gần giống như RAID 0+1. Thay vì phân chia dữ liệu giữa các thiết lập ổ đĩa rồi mới phản chiếu chúng thì hai ổ cứng đầu tiên sẽ được phản chiếu với nhau. Đây là thiết lập lồng RAID. Hai cặp 1 và 2, 3 và 4 sẽ phản chiếu lẫn nhau. Và cần tối thiểu 4 ổ cứng

<img src="https://camo.githubusercontent.com/8dd8743acac8bd71b70ebdd8dfadd790470613e1/68747470733a2f2f692e696d6775722e636f6d2f70666e795a44372e706e67">

Thuận lợi:

- Tăng hiệu quả thực thi
- Dữ liệu được dự phòng toàn bộ

Bất lợi

- Yêu cần số lượng ổ cứng lớn
- Khả năng truy xuất dữ liệu giảm.

**RAID 5**

RAID này sử dụng phương pháp phân chia "parity" (chẵn lẻ) để duy trì dự phòng dữ liệu. Cần có ít nhất 3 ổ cứng để thực hiện loại RAID này.

<img src="https://camo.githubusercontent.com/d08600856c9db14c7ed906c8fde34ab47a327126/68747470733a2f2f692e696d6775722e636f6d2f556e35335277312e706e67">

P (parity) là dữ liệu lặp lại cho hai khối dữ liệu.

Công thức tính dung lượng của RAID 5: (n-1)xZ= Dung lượng. Trong đó:

- n: là số ổ cứng
- Z: là dung lượng của một ổ cứng

Ví Dụ: Trong trường hợp có 3 ổ cứng với dung lượng mỗi ổ là 500GB thì tổng dung lượng sẽ là: (3-1)x500GB= 1000GB= 1TB

Thuận lợi:

- Tăng dung lượng lưu trữ

- Dữ liệu được dự phòng toàn bộ

Bất lợi

- giá thành cao

- hiệu qủa thực thi giảm trong quá trình phục hồi.

### mdadm

`mdadm` là một công cụ quản lý RAID 

install mdadm on ubuntu and centos
- ubuntu:`$ sudo apt-get install mdadm -y`
- centos: `$ yum install mdadm -y`

Đọc manpape của mdadm

`$ man mdadm`

`mdadm có 7 chức năng, một số thao tác hay được sử dụng là 'create', 'assemble','monitor'.:
- create: tạo một RAID mới
- assemble: tập hợp các thiết bị để tạo raid
- follow hay monitor: theo dõi thiết bị raid
- build:
- grow: thay đổi kích thức của mảng.
- manage: thực hiện các thao tác thành phần của mảng như là thêm ổ đĩa, gỡ bỏ thiết bị error
- misc: thực hiện các thao tác tẩy xóa các superblock cũ, thu thập thông tin.


**Soft RAID in Linux**

Hỗ trợ các chuẩn 0,1,5,6 trong RAID cứng. Sử dụng `mdadm` để quản lý và file `/proc/mdstat` để chứa thông tin real-time
về thiết bị raid.RAID mền cho phép các phân vùng trên một hoặc nhiều ổ cứng khác nhau lại thành một thiết bị raid (hoạt động ở mức phân vùng).

**Install mdadm**

- Đối với Debian/Ubuntu

    Để bắt đầu cài đặt, bạn cần thêm repo bằng cách thực hiện lệnh sau:
    
    `add-apt-repository ppa:eugenesan/ppa`
    
    Tiếp theo cần update hệ thống:
    
    `apt-get update`
    
    Chạy lệnh sau để cài gói `mdadm`
    
    `apt-get install mdadm`
    
- Đối với RHEL/CentOS:
    
    Để cài đặt trước hết cần update hệ thống
    
    `yum update`
    
    Chạy lệnh sau để cài đặt gói `mdadm`

    `yum install mdadm`
    
**Tạo RAID**

Chuẩn bị: hệ thống đã cài `mdadm` cần có ít nhất 2 ổ cứng để chạy raid 1

Check disk bằng câu lệnh:
    
`fdisk -l`
    
    [root@localhost ~]# fdisk -l |grep sd
    Disk /dev/sda: 21.5 GB, 21474836480 bytes, 41943040 sectors
    /dev/sda1   *        2048     2099199     1048576   83  Linux
    /dev/sda2         2099200    41943039    19921920   8e  Linux LVM
    Disk /dev/sdb: 10.7 GB, 10737418240 bytes, 20971520 sectors
    Disk /dev/sdc: 10.7 GB, 10737418240 bytes, 20971520 sectors
  
    
 Qua lệnh kiểm tra trên chúng ta thấy có 2 đĩa cứng mới được phát hiện, bây giờ chúng ta thực hiện kiểm tra xem các ổ cứng có sử dụng RAID nào chưa bằng lệnh mdadm cùng với tùy chọn --examine như bên dưới.
    
    [root@localhost ~]# mdadm --examine /dev/sd[b-c]
    mdadm: No md superblock detected on /dev/sdb.
    mdadm: No md superblock detected on /dev/sdc.
    
Kết quả cho thấy không có RAID nào được cài trên hai ổ đó

Tiếp theo: Tạo phân vùng ổ cứng

Tạo phân vùng trên ổ đĩa sdb còn sdc tương tự

Chạy lệnh fdisk /dev/sdb để tạo phân vùng cho `sdb` thực hiện các thao tác sau:
- Nhấn `n` để tạo một phân vùng mới
- Sau đó chọn `p` cho phân vùng chính (Nhấn enter để chọn default)
- Tiếp theo nhấn chọn số phân vùng là 1 (Nhấn enter để chọn default)
- Nhập First Sector: default là 2048
- Nhập Last sector: +[Số GB bạn muốn tạo cho phân vùng đó]
- Tiếp theo nhấn `p` để in phân vùng đã được tạo

Tạo RAID tự động trên các phân vùng

- Tiếp theo đó nhấn `L` để liệt kê tất cả các loại có sẵn
- Nhấn `t` để chọn phân vùng
- Nhấn fd để chọn Linux RAID tự động và nhấn Enter để áp dụng
- Sử dụng phím `p` để in thay đổi
- Cuối cùng nhấn `w` để lưu các thay đổi

Các thao tác trên được thực hiện như sau:
    
    [root@localhost ~]# fdisk /dev/sdb
    Welcome to fdisk (util-linux 2.23.2).
    
    Changes will remain in memory only, until you decide to write them.
    Be careful before using the write command.
    
    Device does not contain a recognized partition table
    Building a new DOS disklabel with disk identifier 0xd1c9ae6a.
    
    Command (m for help): n
    Partition type:
       p   primary (0 primary, 0 extended, 4 free)
       e   extended
    Select (default p): p
    Partition number (1-4, default 1): 1
    First sector (2048-20971519, default 2048): 2048
    Last sector, +sectors or +size{K,M,G} (2048-20971519, default 20971519): 20971519
    Partition 1 of type Linux and of size 10 GiB is set
    
    Command (m for help): p
    
    Disk /dev/sdb: 10.7 GB, 10737418240 bytes, 20971520 sectors
    Units = sectors of 1 * 512 = 512 bytes
    Sector size (logical/physical): 512 bytes / 512 bytes
    I/O size (minimum/optimal): 512 bytes / 512 bytes
    Disk label type: dos
    Disk identifier: 0xd1c9ae6a
    
    Device Boot      Start         End      Blocks   Id  System
    /dev/sdb1            2048    20971519    10484736   83  Linux
    
    Command (m for help): L
    
     0  Empty           24  NEC DOS         81  Minix / old Lin bf  Solaris
     1  FAT12           27  Hidden NTFS Win 82  Linux swap / So c1  DRDOS/sec (FAT-
     2  XENIX root      39  Plan 9          83  Linux           c4  DRDOS/sec (FAT-
     3  XENIX usr       3c  PartitionMagic  84  OS/2 hidden C:  c6  DRDOS/sec (FAT-
     4  FAT16 <32M      40  Venix 80286     85  Linux extended  c7  Syrinx
     5  Extended        41  PPC PReP Boot   86  NTFS volume set da  Non-FS data
     6  FAT16           42  SFS             87  NTFS volume set db  CP/M / CTOS / .
     7  HPFS/NTFS/exFAT 4d  QNX4.x          88  Linux plaintext de  Dell Utility
     8  AIX             4e  QNX4.x 2nd part 8e  Linux LVM       df  BootIt
     9  AIX bootable    4f  QNX4.x 3rd part 93  Amoeba          e1  DOS access
     a  OS/2 Boot Manag 50  OnTrack DM      94  Amoeba BBT      e3  DOS R/O
     b  W95 FAT32       51  OnTrack DM6 Aux 9f  BSD/OS          e4  SpeedStor
     c  W95 FAT32 (LBA) 52  CP/M            a0  IBM Thinkpad hi eb  BeOS fs
     e  W95 FAT16 (LBA) 53  OnTrack DM6 Aux a5  FreeBSD         ee  GPT
     f  W95 Ext'd (LBA) 54  OnTrackDM6      a6  OpenBSD         ef  EFI (FAT-12/16/
    10  OPUS            55  EZ-Drive        a7  NeXTSTEP        f0  Linux/PA-RISC b
    11  Hidden FAT12    56  Golden Bow      a8  Darwin UFS      f1  SpeedStor
    12  Compaq diagnost 5c  Priam Edisk     a9  NetBSD          f4  SpeedStor
    14  Hidden FAT16 <3 61  SpeedStor       ab  Darwin boot     f2  DOS secondary
    16  Hidden FAT16    63  GNU HURD or Sys af  HFS / HFS+      fb  VMware VMFS
    17  Hidden HPFS/NTF 64  Novell Netware  b7  BSDI fs         fc  VMware VMKCORE
    18  AST SmartSleep  65  Novell Netware  b8  BSDI swap       fd  Linux raid auto
    1b  Hidden W95 FAT3 70  DiskSecure Mult bb  Boot Wizard hid fe  LANstep
    1c  Hidden W95 FAT3 75  PC/IX           be  Solaris boot    ff  BBT
    1e  Hidden W95 FAT1 80  Old Minix
    
    Command (m for help): t
    Selected partition 1
    Hex code (type L to list all codes): fd
    Changed type of partition 'Linux' to 'Linux raid autodetect'
    
    Command (m for help): p
    
    Disk /dev/sdb: 10.7 GB, 10737418240 bytes, 20971520 sectors
    Units = sectors of 1 * 512 = 512 bytes
    Sector size (logical/physical): 512 bytes / 512 bytes
    I/O size (minimum/optimal): 512 bytes / 512 bytes
    Disk label type: dos
    Disk identifier: 0xd1c9ae6a
    
       Device Boot      Start         End      Blocks   Id  System
    /dev/sdb1            2048    20971519    10484736   fd  Linux raid autodetect
    
    Command (m for help): w
    The partition table has been altered!
    
    Calling ioctl() to re-read partition table.
    Syncing disks.


Sau khi chạy xong chạy lệnh `fdisk -l | grep sd` xem phân vung đã được tạo hạy chưa

    Disk /dev/sdb: 10.7 GB, 10737418240 bytes, 20971520 sectors
    /dev/sdb1            2048    20971519    10484736   fd  Linux raid autodetect
    Disk /dev/sdc: 10.7 GB, 10737418240 bytes, 20971520 sectors
    /dev/sdc1            2048    20971519    10484736   fd  Linux raid autodetect

**NOTE**

Check xem có đĩa nào tham gia vào raid không

    [root@localhost ~]# mdadm -E /dev/sd[b-c]
    /dev/sdb:
       MBR Magic : aa55
    Partition[0] :     20969472 sectors at         2048 (type fd)
    /dev/sdc:
       MBR Magic : aa55
    Partition[0] :     20969472 sectors at         2048 (type fd)
    [root@localhost ~]# mdadm -E /dev/sd[b-c]1
    mdadm: No md superblock detected on /dev/sdb1.
    mdadm: No md superblock detected on /dev/sdc1.

Kết quả cho thấy không có bất kỳ RAID nào được xác định trên hai phân vung

Tạo RAID:

Tạo thiết bị RAID1 có tên `/dev/md0` sử dụng lệnh sau:

    [root@localhost ~]# mdadm --create /dev/md0 --level=mirror --raid-devices=2 /dev/sd[b-c]1
    mdadm: Note: this array has metadata at the start and
        may not be suitable as a boot device.  If you plan to
        store '/boot' on this device please ensure that
        your boot-loader understands md/v1.x metadata, or use
        --metadata=0.90
    Continue creating array? y
    mdadm: Defaulting to version 1.2 metadata
    mdadm: array /dev/md0 started.

Trong quá trình hệ thống yêu cầu tạo RAID thì chọn `y`

Check raid và quá trình tạo raid:

    [root@localhost ~]# cat /proc/mdstat
    Personalities : [raid1]
    md0 : active raid1 sdc1[1] sdb1[0]
          10475520 blocks super 1.2 [2/2] [UU]
          [=>...................]  resync =  7.0% (740096/10475520) finish=0.6min speed=246698K/sec
    
    unused devices: <none>
    
Kiểm tra raid mới được tạo:

    [root@localhost ~]# mdadm --detail /dev/md0
    /dev/md0:
               Version : 1.2
         Creation Time : Sun May 19 13:34:48 2019
            Raid Level : raid1
            Array Size : 10475520 (9.99 GiB 10.73 GB)
         Used Dev Size : 10475520 (9.99 GiB 10.73 GB)
          Raid Devices : 2
         Total Devices : 2
           Persistence : Superblock is persistent
    
           Update Time : Sun May 19 13:35:41 2019
                 State : clean
        Active Devices : 2
       Working Devices : 2
        Failed Devices : 0
         Spare Devices : 0
    
    Consistency Policy : resync
    
                  Name : localhost.localdomain:0  (local to host localhost.localdomain)
                  UUID : 6e8d46d8:d307ecf4:13ec9c89:52955fe6
                Events : 17
    
        Number   Major   Minor   RaidDevice State
           0       8       17        0      active sync   /dev/sdb1
           1       8       33        1      active sync   /dev/sdc1

Tạo file system (ext4) cho thiết bị raid
    
`mkfs.ext4 /dev/md0`

Tạo một thư mục để mount raid mới tạo

`mfdir data`
    
`mount /dev/md0 /data`

Để tự động gắn kết /dev/md0 khi khởi động lại hệ thống chúng ta cần tạo một mục trong tệp /etc/fstab, 
và thêm dòng sau vào

 `/dev/md0       /root/data/   ext4    defaults         0 0`

Sau khi lưu lại trong thư mục `/etc/fstab` thì kiểm tra xem có bất kỳ error nào không.
    
`mount -a`
và
`mount -av`

Nếu không có lỗi nào thì có thể khởi động lại server còn không thì không khởi động lại server để tránh tình trạng không bật được server


Lưu cấu hình RAID thủ công:

Đối với CentOS:

`mdadm --detail --scan --verbose >> /etc/mdadm.conf`

Đối với Ubuntu:

`sudo mdadm --detail --scan | sudo tee -a /etc/mdadm/mdadm.conf`
    
`cat /etc/mdadm.conf`# xem cấu hình mảng raid centos

`cat /etc/mdadm/mdadm.conf`# xem cấu hình mảng raid ubuntu`

Kiểm tra RAID

`mdadm --detail /dev/md0`

        [root@localhost ~]# mdadm --detail /dev/md0
    /dev/md0:
               Version : 1.2
         Creation Time : Sun May 19 13:34:48 2019
            Raid Level : raid1
            Array Size : 10475520 (9.99 GiB 10.73 GB)
         Used Dev Size : 10475520 (9.99 GiB 10.73 GB)
          Raid Devices : 2
         Total Devices : 2
           Persistence : Superblock is persistent
    
           Update Time : Sun May 19 13:39:36 2019
                 State : clean
        Active Devices : 2
       Working Devices : 2
        Failed Devices : 0
         Spare Devices : 0
    
    Consistency Policy : resync
    
                  Name : localhost.localdomain:0  (local to host localhost.localdomain)
                  UUID : 6e8d46d8:d307ecf4:13ec9c89:52955fe6
                Events : 17
    
        Number   Major   Minor   RaidDevice State
           0       8       17        0      active sync   /dev/sdb1
           1       8       33        1      active sync   /dev/sdc1

**Show kết quả quá của RAID1 on Ubuntu**

<img src="https://i.imgur.com/X4KNHEr.jpg">


Tham khảo

[1] https://uet.vnu.edu.vn/~thanhld/lects/netos/bai12-LVM-RAID.pdf

[2] https://github.com/utnguyen153s2/Linux-Admin/blob/master/04.Disk%20management/4.6%20LVM.md

[3] https://blogd.net/linux/software-raid-toan-tap-tren-linux/

[4] https://techblog.vn/lam-the-nao-de-tao-mang-raid-voi-mdadm-tren-ubuntu-1804